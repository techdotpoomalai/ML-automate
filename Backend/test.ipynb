{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>industry_code_ANZSIC</th>\n",
       "      <th>industry_name_ANZSIC</th>\n",
       "      <th>rme_size_grp</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Activity unit</td>\n",
       "      <td>46134</td>\n",
       "      <td>COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Rolling mean employees</td>\n",
       "      <td>0</td>\n",
       "      <td>COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Salaries and wages paid</td>\n",
       "      <td>279</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Sales, government funding, grants and subsidies</td>\n",
       "      <td>8187</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Total income</td>\n",
       "      <td>8866</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20119</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Total income</td>\n",
       "      <td>930995</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Total expenditure</td>\n",
       "      <td>832964</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20121</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Operating profit before tax</td>\n",
       "      <td>103616</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20122</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Total assets</td>\n",
       "      <td>2831894</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Fixed tangible assets</td>\n",
       "      <td>681890</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20124 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year industry_code_ANZSIC               industry_name_ANZSIC  \\\n",
       "0      2011                    A  Agriculture, Forestry and Fishing   \n",
       "1      2011                    A  Agriculture, Forestry and Fishing   \n",
       "2      2011                    A  Agriculture, Forestry and Fishing   \n",
       "3      2011                    A  Agriculture, Forestry and Fishing   \n",
       "4      2011                    A  Agriculture, Forestry and Fishing   \n",
       "...     ...                  ...                                ...   \n",
       "20119  2023                  all                     All Industries   \n",
       "20120  2023                  all                     All Industries   \n",
       "20121  2023                  all                     All Industries   \n",
       "20122  2023                  all                     All Industries   \n",
       "20123  2023                  all                     All Industries   \n",
       "\n",
       "        rme_size_grp                                         variable  \\\n",
       "0                a_0                                    Activity unit   \n",
       "1                a_0                           Rolling mean employees   \n",
       "2                a_0                          Salaries and wages paid   \n",
       "3                a_0  Sales, government funding, grants and subsidies   \n",
       "4                a_0                                     Total income   \n",
       "...              ...                                              ...   \n",
       "20119  j_Grand_Total                                     Total income   \n",
       "20120  j_Grand_Total                                Total expenditure   \n",
       "20121  j_Grand_Total                      Operating profit before tax   \n",
       "20122  j_Grand_Total                                     Total assets   \n",
       "20123  j_Grand_Total                            Fixed tangible assets   \n",
       "\n",
       "         value               unit  \n",
       "0        46134              COUNT  \n",
       "1            0              COUNT  \n",
       "2          279  DOLLARS(millions)  \n",
       "3         8187  DOLLARS(millions)  \n",
       "4         8866  DOLLARS(millions)  \n",
       "...        ...                ...  \n",
       "20119   930995  DOLLARS(millions)  \n",
       "20120   832964  DOLLARS(millions)  \n",
       "20121   103616  DOLLARS(millions)  \n",
       "20122  2831894  DOLLARS(millions)  \n",
       "20123   681890  DOLLARS(millions)  \n",
       "\n",
       "[20124 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeAutomate\n\u001b[1;32m      8\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPreprocess\u001b[39;00m(CodeAutomate):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from load_data import CodeAutomate\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "class Preprocess(CodeAutomate):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prepros_record={}\n",
    "\n",
    "    def get_data(self):\n",
    "        self.prepros_record={\n",
    "            'onehot_encode':[],\n",
    "            'label_encode':[],\n",
    "            'drop_col':[]\n",
    "        }\n",
    "        return super().get_data()\n",
    "\n",
    "    def process(self,col,prepros,onehot_encoder):\n",
    "        col_dict=json.loads(col)\n",
    "        cols=[key for key, value in col_dict.items() if value]\n",
    "        # try:\n",
    "        t=None\n",
    "        df = pd.read_csv(f\"preprocess.csv\")\n",
    "        if prepros == 'onehot_encode':\n",
    "            for name in cols:\n",
    "                encoded = onehot_encoder.fit_transform(df[[name]])\n",
    "                encoded_colunms=onehot_encoder.get_feature_names_out([name])\n",
    "                df.pop(name)\n",
    "                feature_names=onehot_encoder.get_feature_names_out([name])\n",
    "                encoder_feature=pd.DataFrame(encoded.toarray(),columns=feature_names)\n",
    "                df=pd.concat([encoder_feature, df], axis=1)\n",
    "                t=onehot_encoder.fit(df[[name]])\n",
    "            \n",
    "            temp=[]\n",
    "            if self.prepros_record['onehot_encode']:\n",
    "                temp=self.prepros_record['onehot_encode']\n",
    "            temp.extend(cols)\n",
    "            self.prepros_record['onehot_encode']=temp\n",
    "            \n",
    "\n",
    "        #     elif prepros == 'label_encode':\n",
    "        #         for col in cols:\n",
    "        #             if col in df.columns:\n",
    "        #                 df[col] = label_encoder.fit_transform(df[col])\n",
    "            \n",
    "        #         temp=[]\n",
    "        #         if self.prepros_record['label_encode']:\n",
    "        #             temp=self.prepros_record['label_encode']\n",
    "        #         temp.extend(cols)\n",
    "        #         self.prepros_record['label_encode']=temp\n",
    "                \n",
    "        #     elif prepros == 'drop_col':\n",
    "        #         df.drop(columns=cols, errors='ignore', inplace=True)\n",
    "\n",
    "        #         temp=[]\n",
    "        #         if self.prepros_record['drop_col']:\n",
    "        #             temp=self.prepros_record['drop_col']\n",
    "        #         temp.extend(cols)\n",
    "        #         self.prepros_record['drop_col']=temp            \n",
    "\n",
    "        bool_col=[col for col in df.columns if df[col].dtype == 'bool']\n",
    "        for col_ in bool_col:\n",
    "            df[col_] = df[col_].astype(int)\n",
    "        df.to_csv(f\"preprocess.csv\",index=False)  \n",
    "        records = df.to_dict(\"records\")\n",
    "        with open(\"preprocess_record.json\", \"w\") as json_file:\n",
    "            json.dump(self.prepros_record, json_file, indent=4) \n",
    "        return records,t\n",
    "        # except:\n",
    "        #     return []\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from preprocess import Preprocess\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder=OneHotEncoder()\n",
    "\n",
    "class Prediction(Preprocess):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.onehot_encode=None\n",
    "\n",
    "    def get_data(self):\n",
    "        return super().get_data()\n",
    "    \n",
    "    def process(self, col, prepros):\n",
    "        records,self.onehot_encode=super().process(col, prepros, onehot_encoder)\n",
    "        # print(self.onehot_encode)\n",
    "        # print(records)\n",
    "        return records\n",
    "    \n",
    "    def get_json_input(self,):\n",
    "        json_input={\n",
    "            \"number\":[],\n",
    "            \"text\":[]\n",
    "        }\n",
    "        try:\n",
    "            df = pd.read_csv(f\"data.csv\")\n",
    "            cols=df.columns.to_list()\n",
    "            temp1={}\n",
    "            for col in cols:\n",
    "                if df[col].dtype == object:\n",
    "                    temp2=df[col].unique().tolist()\n",
    "                    temp1[col]=temp2\n",
    "                else:\n",
    "                    json_input[\"number\"].append(col)\n",
    "            json_input[\"text\"]=temp1\n",
    "            return json_input\n",
    "        except:\n",
    "            return {\"message\":\"fail\"}\n",
    "\n",
    "    def find(self,pridict_input):\n",
    "        data = json.loads(pridict_input)\n",
    "        df1=pd.DataFrame(list([data.values()]),columns=list(data.keys()))\n",
    "        print(self.onehot_encoder.transform(df1[['gender']]))\n",
    "\n",
    "        # for col in df1.columns.to_list():\n",
    "        #     df1[col] = label_encoder.fit_transform(df1[col])  \n",
    "        # print(df1) \n",
    "        # try:\n",
    "        #     with open(f\"model.pkl\", 'rb') as file:\n",
    "        #         loaded_object = pickle.load(file)\n",
    "        #     print(df1.values)\n",
    "        #     predict=loaded_object.predict(df1.values)\n",
    "        #     return {\"prediction\":str(predict[0])}\n",
    "        # except:\n",
    "        #     return {\"message\":\"error\"}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['gender', 'race/ethnicity'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m      5\u001b[0m onehot_encoder\u001b[38;5;241m=\u001b[39mOneHotEncoder()\n\u001b[0;32m----> 7\u001b[0m onehot\u001b[38;5;241m=\u001b[39monehot_encoder\u001b[38;5;241m.\u001b[39mfit(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace/ethnicity\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      8\u001b[0m test\u001b[38;5;241m=\u001b[39monehot\u001b[38;5;241m.\u001b[39mtransform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace/ethnicity\u001b[39m\u001b[38;5;124m'\u001b[39m]][:\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m      9\u001b[0m test\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['gender', 'race/ethnicity'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder=OneHotEncoder()\n",
    "\n",
    "onehot=onehot_encoder.fit(df[['gender','race/ethnicity']])\n",
    "test=onehot.transform(df[['gender','race/ethnicity']][:4])\n",
    "test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample data with multiple categorical columns\n",
    "data =pd.read_csv('data.csv')\n",
    "data=data.drop([\"math score\",\"reading score\",\"writing score\"],axis=1)\n",
    "def label_encode(df):\n",
    "    label_encoders = {}\n",
    "    for column in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        label_encoders[column] = le\n",
    "    return df\n",
    "\n",
    "# Use FunctionTransformer to apply the custom function in ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', FunctionTransformer(label_encode), data.columns)  # Apply LabelEncoder\n",
    "    ])\n",
    "\n",
    "# Transform the data\n",
    "encoded_data = preprocessor.fit_transform(data.copy())\n",
    "\n",
    "# Convert back to a DataFrame for readability\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=data.columns)\n",
    "\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m,:])\n\u001b[1;32m      2\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(encoded_data, columns\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoded_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_data = preprocessor.fit_transform(data.iloc[0:5,:])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=data.columns)\n",
    "\n",
    "print(encoded_df)\n",
    "print(data.iloc[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race/ethnicity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:361\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 361\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race/ethnicity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     24\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     25\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_label\u001b[39m\u001b[38;5;124m'\u001b[39m, FunctionTransformer(label_encode), cols2),  \u001b[38;5;66;03m# Apply label encoding to cols1\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_onehot\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(), cols1)  \u001b[38;5;66;03m# Apply OneHotEncoder to cols2\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     ])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Apply the transformation\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:,:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Convert encoded_data to DataFrame for better readability\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# OneHotEncoder output is a sparse matrix by default, so convert it to dense\u001b[39;00m\n\u001b[1;32m     34\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(encoded_data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:968\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m    966\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:536\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    534\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    535\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 536\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m _get_column_indices(X, columns)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:369\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    366\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Sample data with multiple categorical columns\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Define the label encoding function (for specific columns in cols1)\n",
    "def label_encode(X):\n",
    "    X = pd.DataFrame(X)  # Convert to DataFrame for ease\n",
    "    for column in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "    return X\n",
    "\n",
    "# OneHotEncoder will be used directly from sklearn for columns in cols2\n",
    "\n",
    "# Specify the columns for label encoding and one-hot encoding\n",
    "cols1 = ['gender']    # Columns for Label Encoding\n",
    "cols2 = ['race/ethnicity']   # Columns for One-Hot Encoding\n",
    "\n",
    "# Use ColumnTransformer to apply different encodings\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', FunctionTransformer(label_encode), cols2),  # Apply label encoding to cols1\n",
    "        ('cat_onehot', OneHotEncoder(), cols1)  # Apply OneHotEncoder to cols2\n",
    "    ])\n",
    "\n",
    "# Apply the transformation\n",
    "encoded_data = preprocessor.fit_transform(data.iloc[-10:,:2])\n",
    "\n",
    "# Convert encoded_data to DataFrame for better readability\n",
    "# OneHotEncoder output is a sparse matrix by default, so convert it to dense\n",
    "encoded_df = pd.DataFrame(encoded_data)\n",
    "\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>industry_code_ANZSIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20114</th>\n",
       "      <td>2023</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20115</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20116</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20117</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20118</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20119</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20121</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20122</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year industry_code_ANZSIC\n",
       "20114  2023                    S\n",
       "20115  2023                  all\n",
       "20116  2023                  all\n",
       "20117  2023                  all\n",
       "20118  2023                  all\n",
       "20119  2023                  all\n",
       "20120  2023                  all\n",
       "20121  2023                  all\n",
       "20122  2023                  all\n",
       "20123  2023                  all"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-10:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:361\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 361\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     22\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     23\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_label\u001b[39m\u001b[38;5;124m'\u001b[39m, FunctionTransformer(label_encode), cols1),  \u001b[38;5;66;03m# Apply label encoding to cols1\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_onehot\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(), cols2)  \u001b[38;5;66;03m# Apply OneHotEncoder to cols2\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     ])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fit the transformer on the data\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m preprocessor\u001b[38;5;241m.\u001b[39mfit(data)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Get the names of the one-hot encoded columns\u001b[39;00m\n\u001b[1;32m     31\u001b[0m onehot_columns \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransformers_[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out(cols2)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:922\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    919\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_transform(X, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:968\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m    966\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:536\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    534\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    535\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 536\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m _get_column_indices(X, columns)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:369\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    366\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Sample data with multiple categorical columns\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Define the label encoding function (for specific columns in cols1)\n",
    "def label_encode(X):\n",
    "    X = pd.DataFrame(X)  # Convert to DataFrame for ease\n",
    "    for column in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "    return X\n",
    "\n",
    "# Specify the columns for label encoding and one-hot encoding\n",
    "cols1 = ['gender']    # Columns for Label Encoding\n",
    "cols2 = []   # Columns for One-Hot Encoding\n",
    "\n",
    "# Use ColumnTransformer to apply different encodings\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_label', FunctionTransformer(label_encode), cols1),  # Apply label encoding to cols1\n",
    "        ('cat_onehot', OneHotEncoder(), cols2)  # Apply OneHotEncoder to cols2\n",
    "    ])\n",
    "\n",
    "# Fit the transformer on the data\n",
    "preprocessor.fit(data)\n",
    "\n",
    "# Get the names of the one-hot encoded columns\n",
    "onehot_columns = preprocessor.transformers_[1][1].get_feature_names_out(cols2)\n",
    "\n",
    "# Combine label-encoded columns and one-hot encoded column names\n",
    "final_columns = cols1 + list(onehot_columns)\n",
    "\n",
    "# Apply the transformation\n",
    "encoded_data = preprocessor.transform(data.iloc[10:12,:])\n",
    "\n",
    "# Convert encoded_data to DataFrame for better readability\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=final_columns)\n",
    "\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>industry_code_ANZSIC</th>\n",
       "      <th>industry_name_ANZSIC</th>\n",
       "      <th>rme_size_grp</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Activity unit</td>\n",
       "      <td>46134</td>\n",
       "      <td>COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Rolling mean employees</td>\n",
       "      <td>0</td>\n",
       "      <td>COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Salaries and wages paid</td>\n",
       "      <td>279</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Sales, government funding, grants and subsidies</td>\n",
       "      <td>8187</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>A</td>\n",
       "      <td>Agriculture, Forestry and Fishing</td>\n",
       "      <td>a_0</td>\n",
       "      <td>Total income</td>\n",
       "      <td>8866</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20119</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Total income</td>\n",
       "      <td>930995</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Total expenditure</td>\n",
       "      <td>832964</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20121</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Operating profit before tax</td>\n",
       "      <td>103616</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20122</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Total assets</td>\n",
       "      <td>2831894</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>2023</td>\n",
       "      <td>all</td>\n",
       "      <td>All Industries</td>\n",
       "      <td>j_Grand_Total</td>\n",
       "      <td>Fixed tangible assets</td>\n",
       "      <td>681890</td>\n",
       "      <td>DOLLARS(millions)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20124 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year industry_code_ANZSIC               industry_name_ANZSIC  \\\n",
       "0      2011                    A  Agriculture, Forestry and Fishing   \n",
       "1      2011                    A  Agriculture, Forestry and Fishing   \n",
       "2      2011                    A  Agriculture, Forestry and Fishing   \n",
       "3      2011                    A  Agriculture, Forestry and Fishing   \n",
       "4      2011                    A  Agriculture, Forestry and Fishing   \n",
       "...     ...                  ...                                ...   \n",
       "20119  2023                  all                     All Industries   \n",
       "20120  2023                  all                     All Industries   \n",
       "20121  2023                  all                     All Industries   \n",
       "20122  2023                  all                     All Industries   \n",
       "20123  2023                  all                     All Industries   \n",
       "\n",
       "        rme_size_grp                                         variable  \\\n",
       "0                a_0                                    Activity unit   \n",
       "1                a_0                           Rolling mean employees   \n",
       "2                a_0                          Salaries and wages paid   \n",
       "3                a_0  Sales, government funding, grants and subsidies   \n",
       "4                a_0                                     Total income   \n",
       "...              ...                                              ...   \n",
       "20119  j_Grand_Total                                     Total income   \n",
       "20120  j_Grand_Total                                Total expenditure   \n",
       "20121  j_Grand_Total                      Operating profit before tax   \n",
       "20122  j_Grand_Total                                     Total assets   \n",
       "20123  j_Grand_Total                            Fixed tangible assets   \n",
       "\n",
       "         value               unit  \n",
       "0        46134              COUNT  \n",
       "1            0              COUNT  \n",
       "2          279  DOLLARS(millions)  \n",
       "3         8187  DOLLARS(millions)  \n",
       "4         8866  DOLLARS(millions)  \n",
       "...        ...                ...  \n",
       "20119   930995  DOLLARS(millions)  \n",
       "20120   832964  DOLLARS(millions)  \n",
       "20121   103616  DOLLARS(millions)  \n",
       "20122  2831894  DOLLARS(millions)  \n",
       "20123   681890  DOLLARS(millions)  \n",
       "\n",
       "[20124 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv(\"preprocess.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20124 entries, 0 to 20123\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   year                  20124 non-null  int64 \n",
      " 1   industry_code_ANZSIC  20124 non-null  object\n",
      " 2   industry_name_ANZSIC  20124 non-null  object\n",
      " 3   rme_size_grp          20124 non-null  object\n",
      " 4   variable              20124 non-null  object\n",
      " 5   value                 20124 non-null  object\n",
      " 6   unit                  20124 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20124 entries, 0 to 20123\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   year                  20124 non-null  int64 \n",
      " 1   industry_code_ANZSIC  20124 non-null  object\n",
      " 2   industry_name_ANZSIC  20124 non-null  object\n",
      " 3   rme_size_grp          20124 non-null  object\n",
      " 4   variable              20124 non-null  object\n",
      " 5   value                 20124 non-null  object\n",
      " 6   unit                  20124 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "des=df1.info()\n",
    "print(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       3 non-null      int64  \n",
      " 1   B       3 non-null      float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 180.0 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def get_dataframe_info(df):\n",
    "    buffer = io.StringIO()\n",
    "    df.info(buf=buffer)  # Capture the output of df.info()\n",
    "    return buffer.getvalue()  # Return it as a string\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\"A\": [1, 2, 3], \"B\": [4.5, 5.5, 6.5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "info_str = get_dataframe_info(df)\n",
    "print(info_str)  # Prints the DataFrame info as a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
